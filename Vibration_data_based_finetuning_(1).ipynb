{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CamilleLHermine/Fine_tuning_and_patching_raw_vibration/blob/main/Vibration_data_based_finetuning_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ra1LfZNc2JzB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import requests\n",
        "\n",
        "import zipfile\n",
        "import glob\n",
        "from scipy.io import loadmat # To read .mat files\n",
        "\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "from urllib3.exceptions import InsecureRequestWarning\n",
        "\n",
        "import accelerate\n",
        "import torch\n",
        "import transformers\n",
        "from datasets import load_dataset, Dataset, load_from_disk, concatenate_datasets, Features, Value, Sequence, ClassLabel\n",
        "import datasets\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from transformers.integrations import TensorBoardCallback\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import Tensor\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch import optim\n",
        "from torch.nn.modules.loss import CrossEntropyLoss\n",
        "\n",
        "from IPython.core.debugger import set_trace\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NjbcXeV2SWG",
        "outputId": "9f1a941e-80c4-46b0-d2d5-269fb8037a66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jKxOEwr_2XqI"
      },
      "outputs": [],
      "source": [
        "zip_path = '/content/drive/MyDrive/CWRUDataset.zip'\n",
        "extract_dir = 'extracted_mat_files/'\n",
        "\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1VYvrZC2ZgM",
        "outputId": "90db87ae-4c8a-40dd-aa3b-b3e0c0c5a93a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B007_0.mat  B021_1.mat\t IR014_2.mat\t OR007@12_3.mat  OR014@3_0.mat\n",
            "B007_1.mat  B021_2.mat\t IR014_3.mat\t OR007@3_0.mat\t OR014@3_1.mat\n",
            "B007_2.mat  B021_3.mat\t IR021_0.mat\t OR007@3_1.mat\t OR014@3_2.mat\n",
            "B007_3.mat  IR007_0.mat  IR021_1.mat\t OR007@3_2.mat\t OR014@3_3.mat\n",
            "B014_0.mat  IR007_1.mat  IR021_2.mat\t OR007@3_3.mat\t OR014@6_0.mat\n",
            "B014_1.mat  IR007_2.mat  IR021_3.mat\t OR007@6_0.mat\t OR021@3_1.mat\n",
            "B014_2.mat  IR007_3.mat  OR007@12_0.mat  OR007@6_1.mat\t OR021@3_2.mat\n",
            "B014_3.mat  IR014_0.mat  OR007@12_1.mat  OR007@6_2.mat\t OR021@3_3.mat\n",
            "B021_0.mat  IR014_1.mat  OR007@12_2.mat  OR007@6_3.mat\t OR021@6_0.mat\n",
            "B007_0.mat  B014_0.mat\tB021_0.mat  IR007_0.mat  IR014_0.mat  IR021_0.mat\n",
            "B007_1.mat  B014_1.mat\tB021_1.mat  IR007_1.mat  IR014_1.mat  IR021_1.mat\n",
            "B007_2.mat  B014_2.mat\tB021_2.mat  IR007_2.mat  IR014_2.mat  IR021_2.mat\n",
            "B007_3.mat  B014_3.mat\tB021_3.mat  IR007_3.mat  IR014_3.mat  IR021_3.mat\n",
            "B007_0.mat  B028_0.mat\t IR021_0.mat\t OR007@3_0.mat\tOR021@12_0.mat\n",
            "B007_1.mat  B028_1.mat\t IR021_1.mat\t OR007@3_1.mat\tOR021@12_1.mat\n",
            "B007_2.mat  B028_2.mat\t IR021_2.mat\t OR007@3_2.mat\tOR021@12_2.mat\n",
            "B007_3.mat  B028_3.mat\t IR021_3.mat\t OR007@3_3.mat\tOR021@12_3.mat\n",
            "B014_0.mat  IR007_0.mat  IR028_0.mat\t OR007@6_0.mat\tOR021@3_0.mat\n",
            "B014_1.mat  IR007_1.mat  IR028_1.mat\t OR007@6_1.mat\tOR021@3_1.mat\n",
            "B014_2.mat  IR007_2.mat  IR028_2.mat\t OR007@6_2.mat\tOR021@3_2.mat\n",
            "B014_3.mat  IR007_3.mat  IR028_3.mat\t OR007@6_3.mat\tOR021@3_3.mat\n",
            "B021_0.mat  IR014_0.mat  OR007@12_0.mat  OR014@6_0.mat\tOR021@6_0.mat\n",
            "B021_1.mat  IR014_1.mat  OR007@12_1.mat  OR014@6_1.mat\tOR021@6_1.mat\n",
            "B021_2.mat  IR014_2.mat  OR007@12_2.mat  OR014@6_2.mat\tOR021@6_2.mat\n",
            "B021_3.mat  IR014_3.mat  OR007@12_3.mat  OR014@6_3.mat\tOR021@6_3.mat\n",
            "Normal_1.mat  Normal_2.mat  Normal_3.mat\n"
          ]
        }
      ],
      "source": [
        "!ls '/content/extracted_mat_files/CWRU Dataset/Data/12k_FE'\n",
        "!ls '/content/extracted_mat_files/CWRU Dataset/Data/48k_DE'\n",
        "!ls '/content/extracted_mat_files/CWRU Dataset/Data/12k_DE'\n",
        "!ls '/content/extracted_mat_files/CWRU Dataset/Data/Normal'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtQ1ndiu2cpW",
        "outputId": "47f480b9-0073-442e-fc42-6ff6621fdf00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN, Created on: Mon Jan 31 15:29:05 2000',\n",
              " '__version__': '1.0',\n",
              " '__globals__': [],\n",
              " 'X122_DE_time': array([[-0.111192  ],\n",
              "        [-0.08302892],\n",
              "        [-0.04234892],\n",
              "        ...,\n",
              "        [ 0.02586831],\n",
              "        [-0.02837169],\n",
              "        [-0.06759138]]),\n",
              " 'X122_FE_time': array([[-0.09512545],\n",
              "        [-0.07211455],\n",
              "        [-0.02609273],\n",
              "        ...,\n",
              "        [ 0.15409091],\n",
              "        [ 0.07642909],\n",
              "        [-0.01006727]]),\n",
              " 'X122RPM': array([[1796]], dtype=uint16)}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "mat_data = loadmat('/content/extracted_mat_files/CWRU Dataset/Data/48k_DE/B007_0.mat')\n",
        "mat_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "K5T-CKm92fI0"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def extract_data_from_mat(file_path, key=None):\n",
        "    mat_data = loadmat(file_path)\n",
        "    # Remove metadata keys that start with \"__\"\n",
        "    mat_keys = [k for k in mat_data.keys() if not k.startswith(\"__\")]\n",
        "\n",
        "    if key is None:\n",
        "        # Pick first array-like key\n",
        "        key = mat_keys[0]\n",
        "\n",
        "    data = mat_data[key]\n",
        "\n",
        "    # Convert to torch tensor\n",
        "    if data.ndim == 1:\n",
        "        data = data.reshape(-1, 1)\n",
        "    else:\n",
        "        data = data[:, 0].reshape(-1, 1)\n",
        "        data = data.reshape(-1, 1)\n",
        "\n",
        "\n",
        "    if os.path.basename(file_path).startswith('B'):\n",
        "      label=('Ball')\n",
        "    elif os.path.basename(file_path).startswith('IR'):\n",
        "      label=('Inner race')\n",
        "    elif os.path.basename(file_path).startswith('OR'):\n",
        "      label=('Outer race')\n",
        "    elif os.path.basename(file_path).startswith('Normal'):\n",
        "      label=('Normal')\n",
        "\n",
        "\n",
        "\n",
        "    return data, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AA9A6jCR2jGZ"
      },
      "outputs": [],
      "source": [
        "def load_folder(folder_path, key=None):\n",
        "    all_data = []\n",
        "    labels=[]\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".mat\"):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            data,label = extract_data_from_mat(file_path, key=key)\n",
        "            all_data.append(data)\n",
        "            labels.append(label)\n",
        "\n",
        "    return all_data,labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FGkROoZu2mJN"
      },
      "outputs": [],
      "source": [
        "file_paths = ['/content/extracted_mat_files/CWRU Dataset/Data/48k_DE/', '/content/extracted_mat_files/CWRU Dataset/Data/12k_DE/', '/content/extracted_mat_files/CWRU Dataset/Data/12k_FE/','/content/extracted_mat_files/CWRU Dataset/Data/Normal/']\n",
        "all_data = []\n",
        "all_labels = []\n",
        "freq = []\n",
        "for folder in file_paths:\n",
        "    data, labels = load_folder(folder)\n",
        "    if all_data:\n",
        "      all_data=all_data+data\n",
        "      all_labels=all_labels+labels\n",
        "\n",
        "    else:\n",
        "      all_data=data\n",
        "      all_labels=labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "n-XH556O2u3I"
      },
      "outputs": [],
      "source": [
        "max_length=2048\n",
        "step=512\n",
        "input_chunk=[]\n",
        "target_chunk=[]\n",
        "for i in range(0,len(all_labels)):\n",
        "  for j in range(0,len(all_data[i])-max_length,step):\n",
        "    if len(all_data[i][j:j+max_length])>0:\n",
        "      input_chunk.append(all_data[i][j:j+max_length])\n",
        "      target_chunk.append(all_labels[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU--It-P2v3G",
        "outputId": "edbed713-ae5c-4afa-9968-a6c9e52b4981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2048\n"
          ]
        }
      ],
      "source": [
        "print(len(input_chunk[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muoy3dwM2xMO",
        "outputId": "ae05351b-d8f9-4e7c-c098-4ee1d687a9a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes (mapping): ['Ball' 'Inner race' 'Normal' 'Outer race']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "numeric_labels = encoder.fit_transform(target_chunk)\n",
        "\n",
        "print(f\"Classes (mapping): {encoder.classes_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yNI0M39uYiI7"
      },
      "outputs": [],
      "source": [
        "# --- 1. Define Variables ---\n",
        "window_size = 2048\n",
        "patch_size = 128\n",
        "stride = 8\n",
        "num_patches = (window_size - patch_size) // stride + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iXX-gBCYYXbf"
      },
      "outputs": [],
      "source": [
        "\n",
        "X = np.array(input_chunk).reshape(-1, window_size)\n",
        "y = np.array(numeric_labels)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.1, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.1, random_state=42, stratify=y_train\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1GfDRB3DDzv",
        "outputId": "37b09c91-69de-4fbd-d184-6d64f41d4229"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36906"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "y-U4AjTyYxN4"
      },
      "outputs": [],
      "source": [
        "def instance_normalize(data):\n",
        "    mean = np.mean(data, axis=1, keepdims=True)\n",
        "    std = np.std(data, axis=1, keepdims=True)\n",
        "    # small epsilon to avoid division by zero\n",
        "    return (data - mean) / (std + 1e-6)\n",
        "\n",
        "X_train_norm = instance_normalize(X_train)\n",
        "X_val_norm = instance_normalize(X_val)\n",
        "X_test_norm = instance_normalize(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko3Hsrl3Z6lA",
        "outputId": "87260593-6ab4-41ef-d929-72bf420ac2d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36906"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "len(X_train_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv5eci_KQUOk",
        "outputId": "764f31fb-e6e5-4230-a4f1-37a6dc0a11aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of patched training data: (36906, 241, 128)\n",
            "Shape of patched validation data: (4101, 241, 128)\n",
            "Shape of patched testing data: (4557, 241, 128)\n"
          ]
        }
      ],
      "source": [
        "def create_patches(data, patch_size, stride):\n",
        "    num_samples, window_length = data.shape\n",
        "    num_patches_per_window = (window_length - patch_size) // stride + 1\n",
        "\n",
        "    patches = np.zeros((num_samples, num_patches_per_window, patch_size))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        for j in range(num_patches_per_window):\n",
        "            start_index = j * stride\n",
        "            end_index = start_index + patch_size\n",
        "            patches[i, j, :] = data[i, start_index:end_index]\n",
        "    return patches\n",
        "\n",
        "X_train_patched = create_patches(X_train_norm, patch_size, stride)\n",
        "X_val_patched = create_patches(X_val_norm, patch_size, stride)\n",
        "X_test_patched = create_patches(X_test_norm, patch_size, stride)\n",
        "\n",
        "# Check the final shape: (num_samples, num_patches, patch_size)\n",
        "print(f\"Shape of patched training data: {X_train_patched.shape}\")\n",
        "print(f\"Shape of patched validation data: {X_val_patched.shape}\")\n",
        "print(f\"Shape of patched testing data: {X_test_patched.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "d39IAqe2YAWN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train_patched, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_val_tensor = torch.tensor(X_val_patched, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test_patched, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1FCXKh8_IBbR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, max_len: int = 5000):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            d_model (int): The dimension of the model's embeddings.\n",
        "            max_len (int): The maximum possible sequence length.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # div of 1 / (10000^(2i/d_model))\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x (torch.Tensor): The input tensor (token embeddings) of shape\n",
        "                              (batch_size, sequence_length, d_model).\n",
        "        \"\"\"\n",
        "        # Add the positional encoding to the input tensor.\n",
        "\n",
        "        x = x + self.pe[:x.size(1), :]\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4tR7tKuYKn8c"
      },
      "outputs": [],
      "source": [
        "#'token_embeddings' has shape (batch_size, num_patches, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XDvQTRAOQcNh"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Model, GPT2Config\n",
        "\n",
        "d_model = 768 # d_model for GPT-2\n",
        "num_classes = len(encoder.classes_) # Number of fault types\n",
        "\n",
        "class VibrationLLM(nn.Module):\n",
        "    def __init__(self, patch_size, d_model, num_patches, num_classes, config):\n",
        "        super().__init__()\n",
        "\n",
        "        # This converts each patch of size 128 into a vector of size d_model (768)\n",
        "        self.token_embedder = nn.Conv1d(in_channels=1, out_channels=config.d_model, kernel_size=config.patch_size, stride=1)\n",
        "        self.config = config\n",
        "        self.pos_encoder = PositionalEncoding(d_model=config.d_model, max_len=config.num_patches + 1)\n",
        "        self.llm_body = GPT2Model.from_pretrained('gpt2')\n",
        "\n",
        "        # FREEZE LLM body\n",
        "        for param in self.llm_body.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Classification Head\n",
        "        self.classifier = nn.Linear(d_model, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, **kwargs):\n",
        "        x=input_ids\n",
        "        # Input x shape: (batch_size, num_patches, patch_size)\n",
        "        # Reshape for Conv1D: (batch_size * num_patches, 1, patch_size)\n",
        "        batch_size, num_patches, patch_size = x.shape\n",
        "        x_reshaped = x.view(-1, 1, patch_size)\n",
        "\n",
        "        token_embeddings = self.token_embedder(x_reshaped)\n",
        "        token_embeddings = token_embeddings.view(batch_size, num_patches, -1)\n",
        "\n",
        "        final_embeddings = self.pos_encoder(token_embeddings)\n",
        "\n",
        "        llm_output = self.llm_body(inputs_embeds=final_embeddings)\n",
        "        hidden_states = llm_output.last_hidden_state\n",
        "\n",
        "        # We use the hidden state of the first patch for classification\n",
        "        pooled_output = hidden_states[:, 0]\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689,
          "referenced_widgets": [
            "fdc39d263d9f4a5c894abbb500989e7c",
            "fbd48c8906094bf38315686675fce17c",
            "e3321244ea6b479095ab4abb1c4fc3a9",
            "d5c36bc5b0a84a95a7d8786624a58b86",
            "7cc0d716c44342c9a4b4d460ad6f8628",
            "08efeccf7fbf40bcbee99808a14f50d8",
            "43a793c93a5a4543990807f6c932193d",
            "52c080e27eaa456f863c1f064a3400f3",
            "b8d90508e0174d31933ce0da1689f08d",
            "d0cd7adeccda4a58849a5aaa51a2db9f",
            "4c70bc18e4ea4859b89729b08ec22703",
            "663fcf435b0b4a82a6ddbeca2a00d60a",
            "86bf08848d3348a0965c91ab1e335d14",
            "9fb8314c30da4f478b9e7188c2870263",
            "713b39891ac5495bb02453a2170237e3",
            "491188b9f4964cfc803f6d4dfb854977",
            "32fbd38dc0494bb7b4f7195e42a5229f",
            "9399d469a3af45caaa6a34293b3a247a",
            "80ecd00be4ed4531b127d3e41b845ed5",
            "7b97f70f155a454fb92e6f084e3f2d09",
            "b1194a13496546789fc5ebf39b2e5028",
            "fb785bd167924725bd7698c13ef6a38a"
          ]
        },
        "id": "YMe-xcwdQjna",
        "outputId": "9568641e-6592-4597-d35d-222cfe4077a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdc39d263d9f4a5c894abbb500989e7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "663fcf435b0b4a82a6ddbeca2a00d60a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VibrationLLM(\n",
            "  (token_embedder): Conv1d(1, 768, kernel_size=(128,), stride=(1,))\n",
            "  (pos_encoder): PositionalEncoding()\n",
            "  (llm_body): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "\n",
        "class ModelConfig:\n",
        "    \"\"\"A simple config class that allows both attribute and dictionary-style access.\"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        for key, value in kwargs.items():\n",
        "            setattr(self, key, value)\n",
        "\n",
        "    def get(self, key, default=None):\n",
        "        return getattr(self, key, default)\n",
        "\n",
        "model_config = ModelConfig(\n",
        "    patch_size= patch_size,\n",
        "    d_model= d_model,\n",
        "    num_patches= num_patches,\n",
        "    num_classes= num_classes,\n",
        "    use_return_dict=True,\n",
        "    tie_word_embeddings= False\n",
        ")\n",
        "\n",
        "model = VibrationLLM(\n",
        "    patch_size=patch_size,\n",
        "    d_model=d_model,\n",
        "    num_patches=num_patches,\n",
        "    num_classes=num_classes,\n",
        "    config=model_config\n",
        ")\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CUMdyhkRfoi",
        "outputId": "2406a588-c247-4879-b2b7-bc6051d11879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 852,484 || all params: 125,394,440 || trainable%: 0.6798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/layer.py:2174: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# We need to tell PEFT which parts of the model to adapt.\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"c_attn\", \"c_proj\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    # Specify the modules to unfreeze and train fully (in addition to LoRA modules)\n",
        "    modules_to_save=['classification',\"ln_f\", \"ln_1\", 'ln_2'], # Common names for LayerNorm in transformers\n",
        "    task_type=TaskType.SEQ_CLS\n",
        ")\n",
        "peft_model = get_peft_model(model, lora_config)\n",
        "\n",
        "peft_model.print_trainable_parameters() #check LoRA is active\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj4ExUsMzegG",
        "outputId": "9d62c694-e4ea-475f-a116-1375a30d9269"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForSequenceClassification(\n",
              "  (base_model): LoraModel(\n",
              "    (model): VibrationLLM(\n",
              "      (token_embedder): Conv1d(1, 768, kernel_size=(128,), stride=(1,))\n",
              "      (pos_encoder): PositionalEncoding()\n",
              "      (llm_body): GPT2Model(\n",
              "        (wte): Embedding(50257, 768)\n",
              "        (wpe): Embedding(1024, 768)\n",
              "        (drop): Dropout(p=0.1, inplace=False)\n",
              "        (h): ModuleList(\n",
              "          (0-11): 12 x GPT2Block(\n",
              "            (ln_1): ModulesToSaveWrapper(\n",
              "              (original_module): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (modules_to_save): ModuleDict(\n",
              "                (default): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              )\n",
              "            )\n",
              "            (attn): GPT2Attention(\n",
              "              (c_attn): lora.Linear(\n",
              "                (base_layer): Conv1D(nf=2304, nx=768)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (c_proj): lora.Linear(\n",
              "                (base_layer): Conv1D(nf=768, nx=768)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (ln_2): ModulesToSaveWrapper(\n",
              "              (original_module): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (modules_to_save): ModuleDict(\n",
              "                (default): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              )\n",
              "            )\n",
              "            (mlp): GPT2MLP(\n",
              "              (c_fc): Conv1D(nf=3072, nx=768)\n",
              "              (c_proj): lora.Linear(\n",
              "                (base_layer): Conv1D(nf=768, nx=3072)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act): NewGELUActivation()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (ln_f): ModulesToSaveWrapper(\n",
              "          (original_module): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (modules_to_save): ModuleDict(\n",
              "            (default): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (classifier): ModulesToSaveWrapper(\n",
              "        (original_module): Linear(in_features=768, out_features=4, bias=True)\n",
              "        (modules_to_save): ModuleDict(\n",
              "          (default): Linear(in_features=768, out_features=4, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "checkpoint_dir = \"my_checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "num_checkpoints = 5\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "peft_model.to(device) # Use the peft_model from now on\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pplZj3jGzi1l",
        "outputId": "e033a155-d6ab-4043-e70b-bd67f6d06358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resuming training from checkpoint: /content/drive/MyDrive/checkpoint_dir/checkpoint_4.pt\n",
            "Loaded model from epoch 4 with loss 0.8603\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(peft_model.parameters(), lr=1e-4)\n",
        "criterion = CrossEntropyLoss()\n",
        "epochs = 5\n",
        "\n",
        "checkpoint_dir = \"/content/drive/MyDrive/checkpoint_dir/\"\n",
        "\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "optimizer = AdamW(peft_model.parameters(), lr=1e-4)\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "start_epoch = 0\n",
        "checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.startswith('checkpoint_')]\n",
        "\n",
        "if checkpoint_files:\n",
        "    latest_checkpoint_path = max(\n",
        "        [os.path.join(checkpoint_dir, f) for f in checkpoint_files],\n",
        "        key=os.path.getctime # Use file creation time to find the most recent\n",
        "    )\n",
        "\n",
        "    print(f\"Resuming training from checkpoint: {latest_checkpoint_path}\")\n",
        "    checkpoint = torch.load(latest_checkpoint_path)\n",
        "\n",
        "    peft_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    last_loss = checkpoint.get('loss', 0.0)\n",
        "    print(f\"Loaded model from epoch {checkpoint['epoch']} with loss {last_loss:.4f}\")\n",
        "else:\n",
        "    print(\"No checkpoint found. Starting training from scratch.\")\n",
        "\n",
        "for epoch in range(start_epoch,epochs):\n",
        "    peft_model.train()\n",
        "    total_train_loss = 0\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "        data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        logits = peft_model(data)\n",
        "        loss = criterion(logits, targets)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Average Training Loss: {total_train_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_{epoch % num_checkpoints}.pt\")\n",
        "\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': peft_model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': total_train_loss / len(train_loader),\n",
        "    }, checkpoint_path)\n",
        "\n",
        "    print(f\"Checkpoint saved to {checkpoint_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    peft_model.eval()\n",
        "    total_val_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    with torch.no_grad(): # Disable gradient calculation to save memory and speed up\n",
        "        for data, targets in val_loader:\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            logits = peft_model(data)\n",
        "            loss = criterion(logits, targets)\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(logits.data, 1)\n",
        "            total_samples += targets.size(0)\n",
        "            correct_predictions += (predicted == targets).sum().item()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    val_accuracy = (correct_predictions / total_samples) * 100\n",
        "    print(f\"Epoch {epoch+1}/{epochs} -> Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        best_model_path = os.path.join(checkpoint_dir, \"best_model.pt\")\n",
        "        torch.save(peft_model.state_dict(), best_model_path)\n",
        "        print(f\"New best model saved to {best_model_path} with validation loss: {best_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "CKATu_rqMBVB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5433dd22-eb75-4114-d634-de3a7eac939a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6182\n",
            "\n"
          ]
        }
      ],
      "source": [
        "peft_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "  for data, targets in test_loader:\n",
        "      data, targets = data.to(device), targets.to(device)\n",
        "      logits = peft_model(data)\n",
        "      preds = torch.argmax(logits, dim=1)\n",
        "      all_preds.extend(preds.cpu().numpy())\n",
        "      all_labels.extend(targets.cpu().numpy())\n",
        "\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fdc39d263d9f4a5c894abbb500989e7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbd48c8906094bf38315686675fce17c",
              "IPY_MODEL_e3321244ea6b479095ab4abb1c4fc3a9",
              "IPY_MODEL_d5c36bc5b0a84a95a7d8786624a58b86"
            ],
            "layout": "IPY_MODEL_7cc0d716c44342c9a4b4d460ad6f8628"
          }
        },
        "fbd48c8906094bf38315686675fce17c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08efeccf7fbf40bcbee99808a14f50d8",
            "placeholder": "​",
            "style": "IPY_MODEL_43a793c93a5a4543990807f6c932193d",
            "value": "config.json: 100%"
          }
        },
        "e3321244ea6b479095ab4abb1c4fc3a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52c080e27eaa456f863c1f064a3400f3",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8d90508e0174d31933ce0da1689f08d",
            "value": 665
          }
        },
        "d5c36bc5b0a84a95a7d8786624a58b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0cd7adeccda4a58849a5aaa51a2db9f",
            "placeholder": "​",
            "style": "IPY_MODEL_4c70bc18e4ea4859b89729b08ec22703",
            "value": " 665/665 [00:00&lt;00:00, 78.2kB/s]"
          }
        },
        "7cc0d716c44342c9a4b4d460ad6f8628": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08efeccf7fbf40bcbee99808a14f50d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43a793c93a5a4543990807f6c932193d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52c080e27eaa456f863c1f064a3400f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8d90508e0174d31933ce0da1689f08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0cd7adeccda4a58849a5aaa51a2db9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c70bc18e4ea4859b89729b08ec22703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "663fcf435b0b4a82a6ddbeca2a00d60a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86bf08848d3348a0965c91ab1e335d14",
              "IPY_MODEL_9fb8314c30da4f478b9e7188c2870263",
              "IPY_MODEL_713b39891ac5495bb02453a2170237e3"
            ],
            "layout": "IPY_MODEL_491188b9f4964cfc803f6d4dfb854977"
          }
        },
        "86bf08848d3348a0965c91ab1e335d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32fbd38dc0494bb7b4f7195e42a5229f",
            "placeholder": "​",
            "style": "IPY_MODEL_9399d469a3af45caaa6a34293b3a247a",
            "value": "model.safetensors: 100%"
          }
        },
        "9fb8314c30da4f478b9e7188c2870263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80ecd00be4ed4531b127d3e41b845ed5",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b97f70f155a454fb92e6f084e3f2d09",
            "value": 548105171
          }
        },
        "713b39891ac5495bb02453a2170237e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1194a13496546789fc5ebf39b2e5028",
            "placeholder": "​",
            "style": "IPY_MODEL_fb785bd167924725bd7698c13ef6a38a",
            "value": " 548M/548M [00:02&lt;00:00, 428MB/s]"
          }
        },
        "491188b9f4964cfc803f6d4dfb854977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32fbd38dc0494bb7b4f7195e42a5229f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9399d469a3af45caaa6a34293b3a247a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80ecd00be4ed4531b127d3e41b845ed5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b97f70f155a454fb92e6f084e3f2d09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1194a13496546789fc5ebf39b2e5028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb785bd167924725bd7698c13ef6a38a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}