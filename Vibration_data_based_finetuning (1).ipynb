{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import zipfile\n",
    "import glob\n",
    "from scipy.io import loadmat # To read .mat files\n",
    "\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "import accelerate\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset, Dataset, load_from_disk, concatenate_datasets, Features, Value, Sequence, ClassLabel\n",
    "import datasets\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "\n",
    "from google.colab import files\n",
    "from google.colab import drive\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import optim\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = '/content/drive/MyDrive/CWRUDataset.zip'\n",
    "extract_dir = 'extracted_mat_files/'\n",
    "\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B007_0.mat  B021_1.mat\t IR014_2.mat\t OR007@12_3.mat  OR014@3_0.mat\n",
      "B007_1.mat  B021_2.mat\t IR014_3.mat\t OR007@3_0.mat\t OR014@3_1.mat\n",
      "B007_2.mat  B021_3.mat\t IR021_0.mat\t OR007@3_1.mat\t OR014@3_2.mat\n",
      "B007_3.mat  IR007_0.mat  IR021_1.mat\t OR007@3_2.mat\t OR014@3_3.mat\n",
      "B014_0.mat  IR007_1.mat  IR021_2.mat\t OR007@3_3.mat\t OR014@6_0.mat\n",
      "B014_1.mat  IR007_2.mat  IR021_3.mat\t OR007@6_0.mat\t OR021@3_1.mat\n",
      "B014_2.mat  IR007_3.mat  OR007@12_0.mat  OR007@6_1.mat\t OR021@3_2.mat\n",
      "B014_3.mat  IR014_0.mat  OR007@12_1.mat  OR007@6_2.mat\t OR021@3_3.mat\n",
      "B021_0.mat  IR014_1.mat  OR007@12_2.mat  OR007@6_3.mat\t OR021@6_0.mat\n",
      "B007_0.mat  B014_0.mat\tB021_0.mat  IR007_0.mat  IR014_0.mat  IR021_0.mat\n",
      "B007_1.mat  B014_1.mat\tB021_1.mat  IR007_1.mat  IR014_1.mat  IR021_1.mat\n",
      "B007_2.mat  B014_2.mat\tB021_2.mat  IR007_2.mat  IR014_2.mat  IR021_2.mat\n",
      "B007_3.mat  B014_3.mat\tB021_3.mat  IR007_3.mat  IR014_3.mat  IR021_3.mat\n",
      "B007_0.mat  B028_0.mat\t IR021_0.mat\t OR007@3_0.mat\tOR021@12_0.mat\n",
      "B007_1.mat  B028_1.mat\t IR021_1.mat\t OR007@3_1.mat\tOR021@12_1.mat\n",
      "B007_2.mat  B028_2.mat\t IR021_2.mat\t OR007@3_2.mat\tOR021@12_2.mat\n",
      "B007_3.mat  B028_3.mat\t IR021_3.mat\t OR007@3_3.mat\tOR021@12_3.mat\n",
      "B014_0.mat  IR007_0.mat  IR028_0.mat\t OR007@6_0.mat\tOR021@3_0.mat\n",
      "B014_1.mat  IR007_1.mat  IR028_1.mat\t OR007@6_1.mat\tOR021@3_1.mat\n",
      "B014_2.mat  IR007_2.mat  IR028_2.mat\t OR007@6_2.mat\tOR021@3_2.mat\n",
      "B014_3.mat  IR007_3.mat  IR028_3.mat\t OR007@6_3.mat\tOR021@3_3.mat\n",
      "B021_0.mat  IR014_0.mat  OR007@12_0.mat  OR014@6_0.mat\tOR021@6_0.mat\n",
      "B021_1.mat  IR014_1.mat  OR007@12_1.mat  OR014@6_1.mat\tOR021@6_1.mat\n",
      "B021_2.mat  IR014_2.mat  OR007@12_2.mat  OR014@6_2.mat\tOR021@6_2.mat\n",
      "B021_3.mat  IR014_3.mat  OR007@12_3.mat  OR014@6_3.mat\tOR021@6_3.mat\n",
      "Normal_1.mat  Normal_2.mat  Normal_3.mat\n"
     ]
    }
   ],
   "source": [
    "!ls '/content/extracted_mat_files/CWRU Dataset/Data/12k_FE'\n",
    "!ls '/content/extracted_mat_files/CWRU Dataset/Data/48k_DE'\n",
    "!ls '/content/extracted_mat_files/CWRU Dataset/Data/12k_DE'\n",
    "!ls '/content/extracted_mat_files/CWRU Dataset/Data/Normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN, Created on: Mon Jan 31 15:29:05 2000',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'X122_DE_time': array([[-0.111192  ],\n",
       "        [-0.08302892],\n",
       "        [-0.04234892],\n",
       "        ...,\n",
       "        [ 0.02586831],\n",
       "        [-0.02837169],\n",
       "        [-0.06759138]]),\n",
       " 'X122_FE_time': array([[-0.09512545],\n",
       "        [-0.07211455],\n",
       "        [-0.02609273],\n",
       "        ...,\n",
       "        [ 0.15409091],\n",
       "        [ 0.07642909],\n",
       "        [-0.01006727]]),\n",
       " 'X122RPM': array([[1796]], dtype=uint16)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_data = loadmat('/content/extracted_mat_files/CWRU Dataset/Data/48k_DE/B007_0.mat')\n",
    "mat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#PB DROP WHEN 2D + IMBALANCED DATA NORMAL + p9 problem\n",
    "\n",
    "def extract_data_from_mat(file_path, key=None):\n",
    "    mat_data = loadmat(file_path)\n",
    "    # Remove metadata keys that start with \"__\"\n",
    "    mat_keys = [k for k in mat_data.keys() if not k.startswith(\"__\")]\n",
    "\n",
    "    if key is None:\n",
    "        # Pick first array-like key\n",
    "        key = mat_keys[0]\n",
    "\n",
    "    data = mat_data[key]\n",
    "\n",
    "    # Convert to torch tensor\n",
    "    if data.ndim == 1:\n",
    "        data = data.reshape(-1, 1)\n",
    "    else:\n",
    "        data = data[:, 0].reshape(-1, 1)\n",
    "        data = data.reshape(-1, 1)\n",
    "\n",
    "\n",
    "    if os.path.basename(file_path).startswith('B'):\n",
    "      label=('Ball')\n",
    "    elif os.path.basename(file_path).startswith('IR'):\n",
    "      label=('Inner race')\n",
    "    elif os.path.basename(file_path).startswith('OR'):\n",
    "      label=('Outer race')\n",
    "    elif os.path.basename(file_path).startswith('Normal'):\n",
    "      label=('Normal')\n",
    "\n",
    "\n",
    "\n",
    "    return data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_folder(folder_path, key=None):\n",
    "    all_data = []\n",
    "    labels=[]\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".mat\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            data,label = extract_data_from_mat(file_path, key=key)\n",
    "            all_data.append(data)\n",
    "            labels.append(label)\n",
    "\n",
    "    return all_data,labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = ['/content/extracted_mat_files/CWRU Dataset/Data/48k_DE/', '/content/extracted_mat_files/CWRU Dataset/Data/12k_DE/', '/content/extracted_mat_files/CWRU Dataset/Data/12k_FE/','/content/extracted_mat_files/CWRU Dataset/Data/Normal/']\n",
    "all_data = []\n",
    "all_labels = []\n",
    "freq = []\n",
    "for folder in file_paths:\n",
    "    data, labels = load_folder(folder)\n",
    "    if all_data:\n",
    "      all_data=all_data+data\n",
    "      all_labels=all_labels+labels\n",
    "\n",
    "    else:\n",
    "      all_data=data\n",
    "      all_labels=labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=2048\n",
    "step=512\n",
    "input_chunk=[]\n",
    "target_chunk=[]\n",
    "for i in range(0,len(all_labels)):\n",
    "  for j in range(0,len(all_data[i])-max_length,step):\n",
    "    if len(all_data[i][j:j+max_length])>0:\n",
    "      input_chunk.append(all_data[i][j:j+max_length])\n",
    "      target_chunk.append(all_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "print(len(input_chunk[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes (mapping): ['Ball' 'Inner race' 'Normal' 'Outer race']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "numeric_labels = encoder.fit_transform(target_chunk)\n",
    "\n",
    "print(f\"Classes (mapping): {encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Define Variables ---\n",
    "window_size = 2048\n",
    "patch_size = 128\n",
    "stride = 8\n",
    "num_patches = (window_size - patch_size) // stride + 1 # This will be 241 patches per window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np.array(input_chunk).reshape(-1, window_size)\n",
    "y = np.array(numeric_labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=42, stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36906"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_normalize(data):\n",
    "    mean = np.mean(data, axis=1, keepdims=True)\n",
    "    std = np.std(data, axis=1, keepdims=True)\n",
    "    # small epsilon to avoid division by zero\n",
    "    return (data - mean) / (std + 1e-6)\n",
    "\n",
    "X_train_norm = instance_normalize(X_train)\n",
    "X_val_norm = instance_normalize(X_val)\n",
    "X_test_norm = instance_normalize(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36906"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of patched training data: (36906, 241, 128)\n",
      "Shape of patched validation data: (4101, 241, 128)\n",
      "Shape of patched testing data: (4557, 241, 128)\n"
     ]
    }
   ],
   "source": [
    "def create_patches(data, patch_size, stride):\n",
    "    num_samples, window_length = data.shape\n",
    "    num_patches_per_window = (window_length - patch_size) // stride + 1\n",
    "\n",
    "    patches = np.zeros((num_samples, num_patches_per_window, patch_size))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        for j in range(num_patches_per_window):\n",
    "            start_index = j * stride\n",
    "            end_index = start_index + patch_size\n",
    "            patches[i, j, :] = data[i, start_index:end_index]\n",
    "    return patches\n",
    "\n",
    "X_train_patched = create_patches(X_train_norm, patch_size, stride)\n",
    "X_val_patched = create_patches(X_val_norm, patch_size, stride)\n",
    "X_test_patched = create_patches(X_test_norm, patch_size, stride)\n",
    "\n",
    "# Check the final shape: (num_samples, num_patches, patch_size)\n",
    "print(f\"Shape of patched training data: {X_train_patched.shape}\")\n",
    "print(f\"Shape of patched validation data: {X_val_patched.shape}\")\n",
    "print(f\"Shape of patched testing data: {X_test_patched.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_patched, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val_patched, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_patched, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            d_model (int): The dimension of the model's embeddings.\n",
    "            max_len (int): The maximum possible sequence length.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "        # div of 1 / (10000^(2i/d_model))\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor (token embeddings) of shape\n",
    "                              (batch_size, sequence_length, d_model).\n",
    "        \"\"\"\n",
    "        # Add the positional encoding to the input tensor.\n",
    "        # x.size(1) is the sequence length of the current batch.\n",
    "        # The positional encoding is sliced to match the input sequence length.\n",
    "        # We add it to the token embeddings before passing to the LLM.\n",
    "        x = x + self.pe[:x.size(1), :]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'token_embeddings' has shape (batch_size, num_patches, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Model, GPT2Config\n",
    "\n",
    "d_model = 768 # d_model for GPT-2\n",
    "num_classes = len(encoder.classes_) # Number of fault types\n",
    "\n",
    "class VibrationLLM(nn.Module):\n",
    "    def __init__(self, patch_size, d_model, num_patches, num_classes, config):\n",
    "        super().__init__()\n",
    "        # Token Embedding Layer (Conv1D)\n",
    "        # This converts each patch of size 128 into a vector of size d_model (768)\n",
    "        self.token_embedder = nn.Conv1d(in_channels=1, out_channels=config.d_model, kernel_size=config.patch_size, stride=1)\n",
    "        self.config = config\n",
    "        self.pos_encoder = PositionalEncoding(d_model=config.d_model, max_len=config.num_patches + 1)\n",
    "        self.llm_body = GPT2Model.from_pretrained('gpt2')\n",
    "\n",
    "        # FREEZE the LLM body as per the paper\n",
    "        for param in self.llm_body.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Classification Head\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, **kwargs):\n",
    "        x=input_ids\n",
    "        # Input x shape: (batch_size, num_patches, patch_size)\n",
    "        # Reshape for Conv1D: (batch_size * num_patches, 1, patch_size)\n",
    "        batch_size, num_patches, patch_size = x.shape\n",
    "        x_reshaped = x.view(-1, 1, patch_size)\n",
    "\n",
    "        token_embeddings = self.token_embedder(x_reshaped)\n",
    "        # Reshape back: (batch_size, num_patches, d_model)\n",
    "        token_embeddings = token_embeddings.view(batch_size, num_patches, -1)\n",
    "\n",
    "        final_embeddings = self.pos_encoder(token_embeddings)\n",
    "\n",
    "        # Pass through the LLM body\n",
    "        llm_output = self.llm_body(inputs_embeds=final_embeddings)\n",
    "        hidden_states = llm_output.last_hidden_state\n",
    "\n",
    "        # We use the hidden state of the first patch for classification\n",
    "        pooled_output = hidden_states[:, 0]\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e12cbe6a4d40b9bea42d4e7e3d6650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6722b055e5b748a085b07587ee939043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VibrationLLM(\n",
      "  (token_embedder): Conv1d(1, 768, kernel_size=(128,), stride=(1,))\n",
      "  (pos_encoder): PositionalEncoding()\n",
      "  (llm_body): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D(nf=2304, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=768)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=3072, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=3072)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "class ModelConfig:\n",
    "    \"\"\"A simple config class that allows both attribute and dictionary-style access.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def get(self, key, default=None):\n",
    "        return getattr(self, key, default)\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    patch_size= patch_size,\n",
    "    d_model= d_model,\n",
    "    num_patches= num_patches,\n",
    "    num_classes= num_classes,\n",
    "    use_return_dict=True,\n",
    "    tie_word_embeddings= False\n",
    ")\n",
    "\n",
    "model = VibrationLLM(\n",
    "    patch_size=patch_size,\n",
    "    d_model=d_model,\n",
    "    num_patches=num_patches,\n",
    "    num_classes=num_classes,\n",
    "    config=model_config\n",
    ")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 852,484 || all params: 125,394,440 || trainable%: 0.6798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/layer.py:2174: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# We need to tell PEFT which parts of the model to adapt.\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    # Specify the modules to unfreeze and train fully (in addition to LoRA modules)\n",
    "    modules_to_save=['classification',\"ln_f\", \"ln_1\", 'ln_2'], # Common names for LayerNorm in transformers\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "\n",
    "peft_model.print_trainable_parameters() #check LoRA is active\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): VibrationLLM(\n",
       "      (token_embedder): Conv1d(1, 768, kernel_size=(128,), stride=(1,))\n",
       "      (pos_encoder): PositionalEncoding()\n",
       "      (llm_body): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): ModulesToSaveWrapper(\n",
       "              (original_module): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (modules_to_save): ModuleDict(\n",
       "                (default): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=2304, nx=768)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=768, nx=768)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): ModulesToSaveWrapper(\n",
       "              (original_module): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (modules_to_save): ModuleDict(\n",
       "                (default): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D(nf=3072, nx=768)\n",
       "              (c_proj): lora.Linear(\n",
       "                (base_layer): Conv1D(nf=768, nx=3072)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): ModulesToSaveWrapper(\n",
       "          (original_module): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (modules_to_save): ModuleDict(\n",
       "            (default): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=4, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = \"my_checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "num_checkpoints = 5\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "peft_model.to(device) # Use the peft_model from now on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found. Starting training from scratch.\n",
      "Epoch 1/5, Average Training Loss: 1.1941\n",
      "Checkpoint saved to my_checkpoints/checkpoint_0.pt\n",
      "Epoch 2/5, Average Training Loss: 1.0363\n",
      "Checkpoint saved to my_checkpoints/checkpoint_1.pt\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(peft_model.parameters(), lr=1e-4)\n",
    "criterion = CrossEntropyLoss()\n",
    "epochs = 5\n",
    "\n",
    "checkpoint_dir = \"/content/drive/MyDrive/checkpoint_dir/\"\n",
    "\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "optimizer = AdamW(peft_model.parameters(), lr=1e-4)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "start_epoch = 0\n",
    "checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.startswith('checkpoint_')]\n",
    "\n",
    "if checkpoint_files:\n",
    "    latest_checkpoint_path = max(\n",
    "        [os.path.join(checkpoint_dir, f) for f in checkpoint_files],\n",
    "        key=os.path.getctime # Use file creation time to find the most recent\n",
    "    )\n",
    "\n",
    "    print(f\"Resuming training from checkpoint: {latest_checkpoint_path}\")\n",
    "    checkpoint = torch.load(latest_checkpoint_path)\n",
    "\n",
    "    peft_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    last_loss = checkpoint.get('loss', 0.0)\n",
    "    print(f\"Loaded model from epoch {checkpoint['epoch']} with loss {last_loss:.4f}\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting training from scratch.\")\n",
    "\n",
    "for epoch in range(start_epoch,epochs):\n",
    "    peft_model.train()\n",
    "    total_train_loss = 0\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = peft_model(data)\n",
    "        loss = criterion(logits, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Average Training Loss: {total_train_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_{epoch % num_checkpoints}.pt\")\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': peft_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': total_train_loss / len(train_loader),\n",
    "    }, checkpoint_path)\n",
    "\n",
    "    print(f\"Checkpoint saved to {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad(): # Disable gradient calculation to save memory and speed up\n",
    "        for data, targets in val_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "            logits = peft_model(data)\n",
    "            loss = criterion(logits, targets)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            total_samples += targets.size(0)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = (correct_predictions / total_samples) * 100\n",
    "    print(f\"Epoch {epoch+1}/{epochs} -> Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model_path = os.path.join(checkpoint_dir, \"best_model.pt\")\n",
    "        torch.save(peft_model.state_dict(), best_model_path)\n",
    "        print(f\"New best model saved to {best_model_path} with validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.eval()\n",
    "  all_preds = []\n",
    "  all_labels = []\n",
    "  with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        logits = peft_model(data)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "  accuracy = accuracy_score(all_labels, all_preds)\n",
    "  print(f\"Epoch {epoch+1}/{epochs}, Test Accuracy: {accuracy:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
